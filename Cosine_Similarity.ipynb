{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Each question in the data has been matched with the 411 possible contexts. The true pair is labeled 1.\n",
    "This created a total of 168921 rows.\n",
    "\n",
    "<br>\n",
    "For each question-context pair, we compute the cosine similarity and then pick the best 50 contexts for each question, .\n",
    "The purpose is to have closely resembling question-context pairs so that BERT can have better data to train on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Desktop/Interactions/AnswerSelectionDataLong.csv', index_col = 0) #data x 411\n",
    "data = pd.read_csv('Desktop/Interactions/formatted_questions.csv') #original data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Am I at risk for COVID-19 from a package or pr...</td>\n",
       "      <td>There is still a lot that is unknown about the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Am I at risk for COVID-19 from a package or pr...</td>\n",
       "      <td>Symptom severity can be influenced by many dif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Am I at risk for COVID-19 from a package or pr...</td>\n",
       "      <td>No. According to the World Health Organization...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am I at risk for COVID-19 from a package or pr...</td>\n",
       "      <td>Scientists are currently testing different typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Am I at risk for COVID-19 from a package or pr...</td>\n",
       "      <td>The existence of an S strain and an L strain r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Am I at risk for COVID-19 from a package or pr...   \n",
       "1  Am I at risk for COVID-19 from a package or pr...   \n",
       "2  Am I at risk for COVID-19 from a package or pr...   \n",
       "3  Am I at risk for COVID-19 from a package or pr...   \n",
       "4  Am I at risk for COVID-19 from a package or pr...   \n",
       "\n",
       "                                             context  label  \n",
       "0  There is still a lot that is unknown about the...      1  \n",
       "1  Symptom severity can be influenced by many dif...      0  \n",
       "2  No. According to the World Health Organization...      0  \n",
       "3  Scientists are currently testing different typ...      0  \n",
       "4  The existence of an S strain and an L strain r...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "def newline_strip(col):   \n",
    "    return col.replace(\"\\n\",\"\")\n",
    "df['context'] = df['context'].apply(newline_strip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word' , stop_words='english',)\n",
    "sklearn_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06999983 0.0590073  0.01970762 ... 0.02458137 0.05146684 0.01594306]\n",
      " [0.03603349 0.17936848 0.01635591 ... 0.04812475 0.11092149 0.1361513 ]\n",
      " [0.05621662 0.05024126 0.34531113 ... 0.03066183 0.04260995 0.00675402]\n",
      " ...\n",
      " [0.0613523  0.03101297 0.04919409 ... 0.023455   0.04361931 0.00251824]\n",
      " [0.         0.         0.02864626 ... 0.09056522 0.03135509 0.        ]\n",
      " [0.047635   0.02054201 0.00919182 ... 0.04119002 0.03632653 0.14408178]]\n"
     ]
    }
   ],
   "source": [
    "cosine_array = np.empty((0,411),int)\n",
    "document_list = df.context[0:411].tolist()                       #make all context documents a list\n",
    "document_list.insert(0,df['question'][0])               #insert first question\n",
    "\n",
    "\n",
    "df_len = len(df)\n",
    "for row in range(0,168921,411):\n",
    "    document_list[0] = df['question'][row]\n",
    "    tfidf_matrix = sklearn_tfidf.fit_transform(document_list)   # fit all documents into TFIDF vector\n",
    "    temp = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])  #compare first document to all documents\n",
    "    cosine_array = np.append(cosine_array, temp, axis=0)\n",
    "print(cosine_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "finish = len(data) -1  # .loc brackets are inclusive\n",
    "increment = len(data)\n",
    "\n",
    "df['cosine_sim'] = \"\"\n",
    "for row in range(411):\n",
    "    cos = cosine_array[row].tolist()\n",
    "    df.loc[start:finish, 'cosine_sim']= cos\n",
    "    start += increment\n",
    "    finish += increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns =['question','context','label','cosine_sim'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(411):\n",
    "    largest = df['cosine_sim'][(row*411):((row+1)*411)].astype(float).nlargest(50)  #get the largest 50 out of each question\n",
    "    ct = 0\n",
    "    for i in largest.index:\n",
    "        if df['label'][i] ==1:       #make sure ground truth is among the largest\n",
    "            ct+=1\n",
    "    if ct == 0:\n",
    "        new_df = new_df.append(df[(row*411):(row+1)*411].loc[df['label'] ==1])\n",
    "        new_df = new_df.append(df.iloc[largest.index][0:49])\n",
    "    else: \n",
    "        new_df = new_df.append(df.iloc[largest.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TRUE labels in Data 596\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for i in new_df['label']:\n",
    "    if i == 1:\n",
    "        ct+=1\n",
    "        \n",
    "print(\"Number of TRUE labels in Data\",ct)     #make sure there are 411 true labels in data    \n",
    "\n",
    "# there are now 596 due to the duplicate contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index(drop=True)\n",
    "new_df.to_csv('AnswerSelectionDataCosine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_df[:16449]\n",
    "test = new_df[16449:]\n",
    "train = train.drop(['cosine_sim'], axis = 1)\n",
    "test = test.drop(['cosine_sim'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('AnswerSelectionDataCosineTrain.tsv',index=False, sep=\"\\t\")\n",
    "test.to_csv('AnswerSelectionDataCosineTest.tsv',index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
